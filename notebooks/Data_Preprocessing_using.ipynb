{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/robeleq/etnltk.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbjL9L0EPXOx",
        "outputId": "a29a73d9-5a37-428f-b2c0-16ff51b5c8ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'etnltk' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd etnltk\n",
        "!pip install .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOuTwvAHPesi",
        "outputId": "f59dd970-d964-4d38-e106-373833c41fc8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/etnltk\n",
            "Processing /content/etnltk\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from etnltk==0.0.26) (0.0.24)\n",
            "Requirement already satisfied: emoji>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from etnltk==0.0.26) (2.14.1)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->etnltk==0.0.26) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->etnltk==0.0.26) (2.2.0)\n",
            "Building wheels for collected packages: etnltk\n",
            "  Building wheel for etnltk (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for etnltk: filename=etnltk-0.0.26-py3-none-any.whl size=33274 sha256=717a2da35c8d411248b75a2d2902574aab3af62ce391790aea39c08b2b2a4445\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-twjh3s2g/wheels/6d/aa/c2/f05ac79cd4ae9c01d7ddc635bb7aac35cf8e2a7095ff88722b\n",
            "Successfully built etnltk\n",
            "Installing collected packages: etnltk\n",
            "  Attempting uninstall: etnltk\n",
            "    Found existing installation: etnltk 0.0.26\n",
            "    Uninstalling etnltk-0.0.26:\n",
            "      Successfully uninstalled etnltk-0.0.26\n",
            "Successfully installed etnltk-0.0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF2IktrjP3uO",
        "outputId": "e9b094f1-5295-47f0-c9a1-d32b34791ef1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N2C00TvNwLq",
        "outputId": "bbd914ad-aa82-4bdc-8044-593bf5944d8e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from etnltk.common.preprocessing import (\n",
        "    remove_emojis, remove_digits, remove_english_chars\n",
        ")\n",
        "from etnltk.common.ethiopic import remove_ethiopic_punctuation\n",
        "from etnltk.lang.am import clean_amharic, normalize\n",
        "from etnltk.tokenize.am import sent_tokenize, word_tokenize\n"
      ],
      "metadata": {
        "id": "pM8DsNjRQM31"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ethioMart/telegram_datas/combined_channels.csv')\n",
        "\n",
        "def preprocess_amharic(text):\n",
        "    try:\n",
        "        normalized = normalize(str(text))\n",
        "        cleaned = clean_amharic(\n",
        "            normalized,\n",
        "            pipeline=[remove_emojis, remove_digits, remove_english_chars, remove_ethiopic_punctuation],\n",
        "            keep_abbrev=False\n",
        "        )\n",
        "        sentences = sent_tokenize(cleaned)\n",
        "        words = word_tokenize(cleaned)\n",
        "        return pd.Series([cleaned, sentences, words])\n",
        "    except:\n",
        "        return pd.Series([\"\", [], []])\n",
        "\n",
        "df[['cleaned_text', 'sentences', 'words']] = df['text'].apply(preprocess_amharic)\n",
        "##df.to_csv('/content/drive/MyDrive/ethioMart/telegram_datas/telegram_cleaned_etnltk.csv', index=False)\n",
        "df.to_csv('/content/drive/MyDrive/ethioMart/telegram_datas/telegram_cleaned_etnltk.csv',\n",
        "          index=False,\n",
        "          encoding='utf-8-sig')\n"
      ],
      "metadata": {
        "id": "PIPFEFmdQSSl"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}